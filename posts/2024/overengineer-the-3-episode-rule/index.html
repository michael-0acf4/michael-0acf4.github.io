<!DOCTYPE html>
<html><head lang="en">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Overengineer the 3 Episode Rule - michael-0acf4</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="How (not) to overengineer the 3 Episode Rule" />
	<meta property="og:image" content=""/>
	<meta property="og:url" content="https://michael-0acf4.github.io/posts/2024/overengineer-the-3-episode-rule/">
  <meta property="og:site_name" content="michael-0acf4">
  <meta property="og:title" content="Overengineer the 3 Episode Rule">
  <meta property="og:description" content="How (not) to overengineer the 3 Episode Rule">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-10-06T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-10-06T00:00:00+00:00">
    <meta property="article:tag" content="Math">
    <meta property="article:tag" content="Random">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Overengineer the 3 Episode Rule">
  <meta name="twitter:description" content="How (not) to overengineer the 3 Episode Rule">
<script src="https://michael-0acf4.github.io/js/feather.min.js"></script>
	
	
        <link href="https://michael-0acf4.github.io/css/fonts.11a1877508139eac0b5b4852ceb110c35641b3533321e66e39149e901ed5756b.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="https://michael-0acf4.github.io/css/main.c294853c9de072489d7f5c0e91f34d78d7725e079212f21f7329840694379c5d.css" />

	
	
		<script type="text/javascript"
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script>
	

	
	
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

		
		<script>
			document.addEventListener("DOMContentLoaded", function() {
					renderMathInElement(document.body, {
							delimiters: [
									{left: "$$", right: "$$", display: true},
									{left: "$", right: "$", display: false}
							]
					});
			});
			</script>
	

	
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="https://michael-0acf4.github.io/">michael-0acf4</a>
	</div>
	<nav>
		
		<a href="/">Home</a>
		
		<a href="/posts">Posts</a>
		
		<a href="/about">About</a>
		
		<a href="/tags">Tags</a>
		
		
	</nav>
</header>

<main>
	<article>
		<div class="title">
			<h1 class="title">Overengineer the 3 Episode Rule</h1>
			<div class="meta">Posted on Oct 6, 2024</div>
		</div>
		

		

		<section class="body">
			<p>As you get older, the number of shows you watch slowly decreases over time. Then, before you realize it, you&rsquo;ve lost the ability to binge-watch multiple seasons in a single day.</p>
<p>This often happens because, even if a show is good, the same tropes are overused. You end up being able to predict what will happen next with a high degree of confidence, which takes away a lot of the fun.</p>
<p>For example, most shounen tend to follow familiar tropes. To be fair, that&rsquo;s part of what defines the genre, but on average, the execution can become so cliché that it diminishes the enjoyment. These shows often appeal more to a less-experienced audience.</p>
<h2 id="the-3-episode-rule">The 3 Episode Rule</h2>
<p>When you start a new anime, you want to give the first 3 episodes a shot. The idea is that the first episode might just set the stage or introduce the characters, and it often takes a bit longer for the story to really kick in. If you&rsquo;re still engaged after three episodes, it’s a good sign that the show is worth your time!</p>
<p>This seems fair for an unbiased mind right?</p>
<p>But here’s the thing: humans are social creatures, and most people are influenced by those around them. When a show becomes really popular, you might find yourself trying to enjoy it, even if it doesn’t necessarily match your taste.</p>
<p>Any show has potential right? You might never have watched a romcom for example, but as push through a good one, by the fourth episode, you might find yourself slowly getting hooked.</p>
<p>So, here’s the dilemma we’ll try to solve:</p>
<blockquote>
<p>Given a show and the general public’s opinion on it, what should its rating be? Is it worth investing your time in?</p>
</blockquote>
<p>In a sense, we are biased by our own tastes, which might cause us to overlook hidden gems. Knowing the opinions of others can help, though we should always prioritize our own enjoyment, of course.</p>
<h2 id="the-math">The math</h2>
<p>Let&rsquo;s model a simple rating $R \in [0, 1]$</p>
<p>$$ R = f(x_1, x_2, .. ,x_N), x_k \in [0, 1] $$</p>
<p>That should account for the following points:</p>
<ol>
<li>
<p>Raw enjoyment (W)</p>
<blockquote>
<p>The willingness to continue is very important!</p>
</blockquote>
</li>
<li>
<p>Story/Plot (S):</p>
<blockquote>
<p>Important, but not as much as the raw enjoyment.
(If you are into the <a href="https://en.wikipedia.org/wiki/Slice_of_life">slice-of-life</a> genre for example)</p>
</blockquote>
</li>
<li>
<p>Public opinion (P):</p>
<blockquote>
<p>Depends on how pertinent it is</p>
</blockquote>
</li>
<li>
<p>Fairness</p>
</li>
</ol>
<p>I would define fairness with the following scheme:</p>
<p>For any uniformly distributed $X = ( x_1  x_2 .. x_N)$ where $x_k$ can take any value from $0$ to $1$ then $E[R=f(X)] = 1/2$.</p>
<p>Which is just a fancy way of saying that if you don&rsquo;t have specific information about how each factor will behave, and you assume they are all randomly distributed between 0 and 1, then on average, the rating would be 50%. This score represents a neutral or balanced result, which might imply it is neither exceptionally good nor bad.</p>
<p>With all of that in mind, here is a proposition:</p>
<p>$ R = f(W, S, P, \rho) = 0.6 \times W + 0.3 \times S + 0.1 \times P \times \rho + 0.1 \times P \times (1−\rho) $</p>
<p>Where $\rho \in [0, 1]$ represents the public pertinence factor or how much you care about the public opinion.</p>
<p>For example if $\rho = 1$, meaning you care 100% about what others think, then our formula reduces to</p>
<p>$ R = f(W, S, P, 1) = 0.6 \times W + 0.3 \times S + 0.1 \times P $</p>
<p>Story/Plot could actually affect the raw enjoyment, one can enjoy a show purely because it has a good plot. That means that $W$ and $S$ are not truly independent from each other, but hey, such edgecase would overcomplicate things and to be fair, in our model that translates into higher $W$ and $S$ score so no big deal.</p>
<p>Now that $W$, $S$, $P$ and $\rho$ are independent from each other, let&rsquo;s verify the 4th point:</p>
<p>$
E[R] = E[0.6 \times W] + E[0.3 \times S] + E[0.1 \times P \times \rho] + E[0.1 \times P \times (1−\rho)]
\newline
E[R] = 0.6 \times E[W] + 0.3 \times E[S] + 0.1 \times E[P] \times E[\rho] + 0.1 \times E[P] \times (1−E[\rho])
\newline
E[R] = 0.6 \times 0.5 + 0.3 \times 0.5 + 0.1 \times 0.5 \times 0.5 + 0.1 \times 0.5 \times (1−0.5)
\newline
E[R] = 0.3 + 0.15 + 0.025 + 0.025 = 0.5 = 1/2
$</p>
<p>Good, that means that if you were to randomly assign values to willingness, story quality, pertinence, and public opinion many times, the average of all the ratings you compute would converge around 50%.</p>
<p>This doesn&rsquo;t mean every rating will be 50%, some ratings will be much higher or lower depending on how those factors vary. However, across all possible scenarios, 50% is the central tendency.</p>
<p>Armed with this, you can rate any show you watch. If your rating is higher than 0.5, it means you&rsquo;ve enjoyed it overall and should continue.</p>
<p>Personally, I set $P = 1$ and instead use the pertinence $\rho$ as a gradual switch, which can be interpreted as how favorable people are toward the show.</p>
<p>You can try to check a someone&rsquo;s rating by asking the following questions:</p>
<ol>
<li>How much are enjoying it now? ($W$)</li>
<li>Is the plot good? How predictable do you feel it is? ($S$)</li>
<li>What do you think others would rate this show? ($P$)</li>
<li>Do you care/or are you aware of what people think? (e.g. through Social Media, memes, ..)  ($\rho$)</li>
</ol>
<h2 id="cumulative-willingness">Cumulative willingness</h2>
<p>Basically, the formula above is used to rate all 3 episodes at once.<br>
But then you may wonder if it is even possible to minimize the time you wasted on a show, so you may ask&hellip;</p>
<blockquote>
<p>Can I watch fewer than 3 episodes without feeling bad about dropping the show?</p>
</blockquote>
<p>Or similarly..</p>
<blockquote>
<p>This show seems to have potential, but 3 episodes is too small a sample.</p>
</blockquote>
<p>We can address this dilemma by rating each episode $ R_e$, and using a <strong>weighted average</strong>.</p>
<ul>
<li>$e$ is the current episode we are on.</li>
<li>$C_e$ is the cumulative rating.</li>
<li>$w(e)$ is the weight for the e-th episode
<ul>
<li>$w(1)$ must be $1$, it&rsquo;s always about first impressions.</li>
<li>$\forall e \in \N*: 0 \lt w(e) \leq 1$.</li>
<li>$\lim_{e \to \infty} w(e) = 0$, the weight must decay to the lower bound as we watch more episodes, i.e. early episodes are the most important.</li>
</ul>
</li>
</ul>
<p><strong>Properties and constraints:</strong></p>
<ol>
<li>$C_1 = R_1 $.</li>
<li>$\forall k: 0 \leq  C_k \leq 1$ .</li>
<li><strong>A not so required requirement.. but is actually nice to have</strong></li>
</ol>
<p>Ok, hear me out. How would our rating behave if each rating up to a certain $k$ is the same?
What if $ R_1 = R_2 = &hellip; = R_k = V$? Then it would be nice to have $C_k = V$ where $V$ is an arbitrary constant.
The main motivation is that if all ratings are the same, then the cumulative rating must hold the same value.</p>
<h3 id="picking-the-right-weighted-average">Picking the right weighted average</h3>
<ul>
<li>The very first episodes are important, so we can rule out the <strong>Harmonic mean</strong> because it tends to give more weight to lower ratings, making it overly sensitive to early episodes with lower weights.</li>
<li>Our ratings are bounded between 0 and 1, the <strong>Geometric mean</strong> is overkill. It is better suited for datasets where values can explode or grow exponentially, which doesn&rsquo;t apply here.</li>
<li>The <strong>Arithmetic mean</strong> on the other hand provides a balanced average and is well-suited for our <strong>bounded</strong> rating model, it is also the simplest. So, let&rsquo;s go with that&hellip;</li>
</ul>
<p>$$
\mu(R) = {{\sum_{i=1}^{e} R_i} \over {e}} = {{\sum_{i=1}^{e} R_i \times 1} \over {\sum_{i=1}^{e} 1}}
\xrightarrow{\text{In weighted form..}}
C_e := {{\sum_{i=1}^{e} R_i w(i)} \over {\sum_{i=1}^{e} w(i)}}
$$</p>
<p><strong>Checking the properties</strong></p>
<ol>
<li>$C_1 = R_1 $. $\checkmark$</li>
<li>$\forall k \in \N^*: 0 \leq  C_k \leq 1$ . $\checkmark$
<em>(The proof is left as an exercice for the reader)</em></li>
<li>$\forall k \in \N^*: R_1 = R_2 = .. = R_k = V \rightarrow C_e = V$  $\checkmark$</li>
</ol>
<p>$$
C_e = {{\sum_{i=1}^{e} V w(i)} \over {\sum_{i=1}^{e} w(i)}} = V
\rightarrow
{{\sum_{i=1}^{e} w(i)} \over {\sum_{i=1}^{e} w(i)}} = 1
$$</p>
<h3 id="picking-a-decent-weight-function">Picking a decent weight function</h3>
<ol>
<li>$w(1)$ = $1$</li>
<li>$\forall e \in \N*: 0 \lt w(e) \leq 1$.</li>
<li>$\lim_{e \to \infty} w(e) = 0$</li>
</ol>
<p>From Req. 2,
$$ 0 \lt w(e) \leq 1 $$
$$ 0 \lt \sum_{i=1}^{k} w(i) \leq k$$</p>
<p><strong>Linear decay</strong></p>
<p>We can rewrite it as $w(1) + r(k) = k$, where $r(k) = -\epsilon \times LinearStuff (\epsilon &gt; 0)$ is the remaining sum.
Furthermore, $r(1)$ must be $0$; we have no remainder at the start.</p>
<p>The simplest candidate is $r(k) = -\epsilon (k - 1)$; it easily verifies $r(1) = 0$. Let&rsquo;s find out if such $\epsilon$ exists and if the other properties defined before are valid.</p>
<p>$$
w(n) = 1 - \epsilon (e - 1)
\rightarrow
\sum_{i=1}^{k} w(i) =  \sum_{i=1}^{k} {1} + \sum_{i=1}^{k} {-\epsilon (i - 1)} = k - \epsilon \sum_{i=1}^{k} {(i - 1)}
$$</p>
<p>$$
\sum_{i=1}^{k} w(i) = k - \epsilon \sum_{i=1}^{k} {(i - 1)} = k
$$</p>
<p>$$
-\epsilon \sum_{i=1}^{k} {(i - 1)} = -\epsilon {(k - 1) k \over 2} = 0
$$</p>
<p>Unfortunately, the equation can only hold if $\epsilon = 0$ or $(k - 1) = 0$ or $k = 0$, no luck I guess. $w(k)$ does not also decay to 0 when $k \rightarrow \infty$, it was doomed from the start.</p>
<p><strong>Exponential decay</strong></p>
<p>Let&rsquo;s steal the well-known radioactive decay function and adjust it a bit&hellip;</p>
<p>$$w(k) := w(1) e^{- \lambda (k - 1)} = e^{- \lambda (k - 1)} $$</p>
<p>We have $w(1) = 1$ and $\lim_{k\to\infty} e^{- \lambda (k - 1)}  = 0$, nice!</p>
<p>Now let&rsquo;s find out if such $\lambda$ exists..</p>
<p>$$w(1) + w(2) + .. + w(k) = e^{- \lambda \times 0 } + e^{- \lambda \times 1 } + e^{- \lambda \times 2 } + &hellip; + e^{- \lambda \times (k - 1) } \leq k  $$</p>
<p>We can easily verify that for any $k$ and $\lambda &gt; 0$, $e^{- \lambda \times (k - 1) } \leq 1$, meaning the sum cannot exceed $k$ (Req. 2).</p>
<p>To answer the question above, any $\lambda &gt; 0$ will work!</p>
<p>As the name suggests, it is exponential. It will decay really fast as we watch more episodes. This seems reasonable and emphasizes the importance of the first episodes.</p>
<p>The average number of episodes for a single season is 12, and to account for that by giving a slower decay within that range of episodes, I decided to set $\lambda$ to $1 / 12$.</p>
<p>For example, if a show has 12 episodes, the weight of the latest episode will be:</p>
<p>$$
w(12) =  e^{- 11 / 12 } = 0.39
$$</p>
<p>Seems nice and all but it lacks &ldquo;concretness&rdquo;, we need to try harder. Let&rsquo;s change the constraint $\sum_i {w(i)} \leq k$ to be stricter $\sum_i {w(i)} = k$.</p>
<p>Then we solve for $\lambda$.</p>
<p>$$
\sum_i {w(i)} = e^{- \lambda \times 0 } + e^{- \lambda \times 1 } + e^{- \lambda \times 2 } + &hellip; + e^{- \lambda \times (k - 1) }
= {{1 - e^{- \lambda k }} \over {1 - e^{-\lambda}}} = k
$$</p>
<p>As you can see, the equation we get is very hard to solve. In fact, since each term is smaller than 1, it is practically
impossible to reach $k$ if we set $k &gt; 1$: $\sum_i {w(i)} \lt k$.
<em>(Also remember, if $\lambda$ is too large, the weight will reach 0 REALLY fast, we need some balance!)</em></p>
<p>We can hack through this by finding an approximation of $\lambda$ which minimizes the difference $k - \sum_i {w(i)}$.</p>
<p>As $k \rightarrow \infty$, $e^{- \lambda k } \rightarrow 0 \lt e^{-\lambda}$.</p>
<p>$$
{{1 - e^{- \lambda k }} \over {1 - e^{-\lambda}}} \approx {{1} \over {1 - e^{-\lambda}}} \lt k
\rightarrow
\lambda_k \lt  -ln(1 - {1 \over k})
$$</p>
<p>We can even go further with this, for <strong>small</strong> $\epsilon$, $ln(1 + \epsilon) \approx \epsilon$.</p>
<p>$$
\lambda \lt -ln(1 - {1 \over k}) \approx -(-1/k) = 1/k
$$</p>
<p>So, one of the best candidate for $\lambda$ we have in order reach the upper bound $k$ as close as possible is $1/k$. The issue with the logarithmic approximation is that it has an edge case at $k = 1$, we can fix that by replacing the first $1$ with $1.0001$ for example but that&rsquo;s needlessly complicated.</p>
<p>In the 12th episode, we have $\lambda_{12} = 1/12$. The main difference with our initial $\lambda$ is that it is now <strong>a function</strong> and not a constant.</p>
<p>Finally, we have:</p>
<p>$$ w(k) = e^{-(1/k) \times (k-1)} = e^{(1 - k)/k}$$</p>
<p>Sadly, Req. 3 will not work as $\lim_{e \to \infty} w(e) = 1/e \approx 0.36 \neq 0 $. :(</p>
<p>Let&rsquo;s not continue further with this. The most trivial approach is to pick an arbitrary constant $\lambda$, but it would be really hard to control the decay factor if our assumptions about how many episodes a show might have are incorrect.</p>
<p><strong>Logarithmic decay</strong></p>
<p>Conceptually, it would be something along the lines of $w(x) = 1 / log_2(x + 1)$, the only issue is that it decays much slower at infinity.</p>
<p>Fortunately, Req. 3 is respected as $\lim_{e \to \infty} w(e) = 0 $.</p>
<p>Same reasoning as the exponential decay above, you can quickly check that for any $k &gt; 1$, $\sum_{i=1}^{k} w(i) &lt; k$.</p>
<p>Let&rsquo;s compare how fast it decays compared to a linear function nonetheless, just to get an idea.</p>
<p>$$
l(x) = -\alpha x \rightarrow {l&rsquo;(x) = -\alpha} (\alpha &gt; 0)
$$</p>
<p>$$
w(x) = {{1} \over {log_2(x + 1)}} \rightarrow {w&rsquo;(x) = -\frac {ln(2)} {(x + 1) ln^2(x + 1)}}
$$</p>
<p>$l$ decays at a constant rate, whereas $w$ decays rapidly for smaller values of $x$ (the logarithm in the denominator takes over). As $x$ gets larger, the linear part will dominate and make $w&rsquo;$ smaller, meaning the original $w$ will decay at a slower rate as $x$ grows. It will eventually also reach $0$. $l(x)$ on the other hand goes to $-\infty$ as it is constantly going &ldquo;down&rdquo;.</p>
<h1 id="conclusion">Conclusion</h1>
<p>If you&rsquo;ve gone through 100 episodes and have a cumulative rating greater than or equal to $0.5$, even if the later episodes were bad, then maybe, overall, you actually liked the show? This is considering we picked a weight function that decays logarithmically reduces as you watch more episodes.</p>
<p>$$ R_e := 0.6 \times W_e + 0.3 \times S_e + 0.1 \times P_e \times \rho_e + 0.1 \times P_e \times (1−\rho_e) $$
$$ w(e) := 1/log_2(e + 1) $$
$$ C_e := {{\sum_{i=1}^{e} R_i w(i)} \over {\sum_{i=1}^{e} w(i)}} $$</p>
<p>For practical purposes, the recursive form for $C_e$ might be easier to calculate if you do this by hand.
As you already know the cumulative rating and weight of latest week&rsquo;s episode.</p>
<p>$$ C_e := {{C_{e-1} {W_{e-1}} + R_e w(e)} \over {W_{e-1} + w(e)}} $$</p>
<p>Where $W_{e-1}$ represents the cumulative sum from previous week&rsquo;s episode, i.e. $W_{e-1} = {\sum_{i=1}^{e-1} w(i)}$</p>

		</section>

		<div class="post-tags">
			
			
			<nav class="nav tags">
				<ul class="tags">
					
					<li><a href="/tags/math">math</a></li>
					
					<li><a href="/tags/random">random</a></li>
					
				</ul>
			</nav>
			
			
		</div>
		</article>
</main>
<footer>
  <div style="display:flex"><a class="soc" href="https://github.com/michael-0acf4" rel="me" title="Github"><i data-feather="github"></i></a>
    <a class="border"></a></div>
  <div class="footer-info">
    2024  © michael-0acf4 
  </div>
</footer>


<script>
  feather.replace()
</script></div>
    </body>
</html>
